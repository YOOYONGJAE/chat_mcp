from django.apps import AppConfig
import os
import torch
import gc

class ChatApiConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'chat_api'

    def ready(self):
        print("ğŸ”§ ì•± ì´ˆê¸°í™” ì¤‘: ìºì‹œ ì •ë¦¬ ìˆ˜í–‰")
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        # â— ì½”ë“œ ë³€ê²½ ê°ì§€ í”„ë¡œì„¸ìŠ¤ì—ì„œëŠ” ëª¨ë¸ ë¡œë”© ìƒëµ
        if os.environ.get('RUN_MAIN') != 'true':
            print("âš ï¸ RUN_MAIN ì•„ë‹˜: ëª¨ë¸ ë¡œë”© ìƒëµ")
            return

        print("ğŸ§  ëª¨ë¸ ë¡œë”© ì‹œì‘")
        from . import llama_loader
        llama_loader.load_model()
