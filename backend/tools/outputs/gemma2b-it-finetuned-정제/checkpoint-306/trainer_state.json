{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 306,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04938271604938271,
      "grad_norm": 5.236988544464111,
      "learning_rate": 1.9921568627450984e-05,
      "loss": 4.9423,
      "step": 5
    },
    {
      "epoch": 0.09876543209876543,
      "grad_norm": 8.832478523254395,
      "learning_rate": 1.9823529411764708e-05,
      "loss": 4.5072,
      "step": 10
    },
    {
      "epoch": 0.14814814814814814,
      "grad_norm": 7.03759241104126,
      "learning_rate": 1.9725490196078433e-05,
      "loss": 4.3347,
      "step": 15
    },
    {
      "epoch": 0.19753086419753085,
      "grad_norm": 4.77068567276001,
      "learning_rate": 1.9627450980392157e-05,
      "loss": 3.7038,
      "step": 20
    },
    {
      "epoch": 0.24691358024691357,
      "grad_norm": 6.592835903167725,
      "learning_rate": 1.9529411764705885e-05,
      "loss": 3.9988,
      "step": 25
    },
    {
      "epoch": 0.2962962962962963,
      "grad_norm": 5.965265274047852,
      "learning_rate": 1.943137254901961e-05,
      "loss": 3.8035,
      "step": 30
    },
    {
      "epoch": 0.345679012345679,
      "grad_norm": 5.966418266296387,
      "learning_rate": 1.9333333333333333e-05,
      "loss": 3.3879,
      "step": 35
    },
    {
      "epoch": 0.3950617283950617,
      "grad_norm": 7.216070175170898,
      "learning_rate": 1.923529411764706e-05,
      "loss": 3.4011,
      "step": 40
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 5.362962245941162,
      "learning_rate": 1.9137254901960786e-05,
      "loss": 3.0191,
      "step": 45
    },
    {
      "epoch": 0.49382716049382713,
      "grad_norm": 5.190781593322754,
      "learning_rate": 1.903921568627451e-05,
      "loss": 2.8071,
      "step": 50
    },
    {
      "epoch": 0.5432098765432098,
      "grad_norm": 3.752577543258667,
      "learning_rate": 1.8941176470588238e-05,
      "loss": 2.5971,
      "step": 55
    },
    {
      "epoch": 0.5925925925925926,
      "grad_norm": 4.068707466125488,
      "learning_rate": 1.8843137254901962e-05,
      "loss": 2.4015,
      "step": 60
    },
    {
      "epoch": 0.6419753086419753,
      "grad_norm": 4.186023712158203,
      "learning_rate": 1.8745098039215686e-05,
      "loss": 2.3719,
      "step": 65
    },
    {
      "epoch": 0.691358024691358,
      "grad_norm": 4.100327491760254,
      "learning_rate": 1.8647058823529414e-05,
      "loss": 1.9586,
      "step": 70
    },
    {
      "epoch": 0.7407407407407407,
      "grad_norm": 4.498850345611572,
      "learning_rate": 1.854901960784314e-05,
      "loss": 2.0735,
      "step": 75
    },
    {
      "epoch": 0.7901234567901234,
      "grad_norm": 3.825822591781616,
      "learning_rate": 1.8450980392156866e-05,
      "loss": 1.6787,
      "step": 80
    },
    {
      "epoch": 0.8395061728395061,
      "grad_norm": 4.208443641662598,
      "learning_rate": 1.8352941176470587e-05,
      "loss": 1.7406,
      "step": 85
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 4.851659297943115,
      "learning_rate": 1.8254901960784315e-05,
      "loss": 1.5269,
      "step": 90
    },
    {
      "epoch": 0.9382716049382716,
      "grad_norm": 4.55633020401001,
      "learning_rate": 1.815686274509804e-05,
      "loss": 1.4541,
      "step": 95
    },
    {
      "epoch": 0.9876543209876543,
      "grad_norm": 3.898806571960449,
      "learning_rate": 1.8058823529411767e-05,
      "loss": 1.3633,
      "step": 100
    },
    {
      "epoch": 1.0296296296296297,
      "grad_norm": 3.9150285720825195,
      "learning_rate": 1.796078431372549e-05,
      "loss": 1.0122,
      "step": 105
    },
    {
      "epoch": 1.0790123456790124,
      "grad_norm": 3.8982677459716797,
      "learning_rate": 1.786274509803922e-05,
      "loss": 1.0192,
      "step": 110
    },
    {
      "epoch": 1.128395061728395,
      "grad_norm": 3.628774642944336,
      "learning_rate": 1.776470588235294e-05,
      "loss": 0.8776,
      "step": 115
    },
    {
      "epoch": 1.1777777777777778,
      "grad_norm": 4.061461925506592,
      "learning_rate": 1.7666666666666668e-05,
      "loss": 0.8145,
      "step": 120
    },
    {
      "epoch": 1.2271604938271605,
      "grad_norm": 6.409433364868164,
      "learning_rate": 1.7568627450980392e-05,
      "loss": 0.6701,
      "step": 125
    },
    {
      "epoch": 1.2765432098765432,
      "grad_norm": 3.9732887744903564,
      "learning_rate": 1.747058823529412e-05,
      "loss": 0.593,
      "step": 130
    },
    {
      "epoch": 1.325925925925926,
      "grad_norm": 3.281608819961548,
      "learning_rate": 1.7372549019607845e-05,
      "loss": 0.5117,
      "step": 135
    },
    {
      "epoch": 1.3753086419753087,
      "grad_norm": 3.134774684906006,
      "learning_rate": 1.7274509803921572e-05,
      "loss": 0.5496,
      "step": 140
    },
    {
      "epoch": 1.4246913580246914,
      "grad_norm": 5.925080299377441,
      "learning_rate": 1.7176470588235293e-05,
      "loss": 0.4126,
      "step": 145
    },
    {
      "epoch": 1.474074074074074,
      "grad_norm": 6.255024433135986,
      "learning_rate": 1.707843137254902e-05,
      "loss": 0.2791,
      "step": 150
    },
    {
      "epoch": 1.5234567901234568,
      "grad_norm": 2.608750104904175,
      "learning_rate": 1.6980392156862745e-05,
      "loss": 0.2786,
      "step": 155
    },
    {
      "epoch": 1.5728395061728395,
      "grad_norm": 4.029676914215088,
      "learning_rate": 1.6882352941176473e-05,
      "loss": 0.2144,
      "step": 160
    },
    {
      "epoch": 1.6222222222222222,
      "grad_norm": 3.8230080604553223,
      "learning_rate": 1.6784313725490198e-05,
      "loss": 0.1617,
      "step": 165
    },
    {
      "epoch": 1.671604938271605,
      "grad_norm": 2.736546277999878,
      "learning_rate": 1.6686274509803922e-05,
      "loss": 0.1516,
      "step": 170
    },
    {
      "epoch": 1.7209876543209877,
      "grad_norm": 2.966341257095337,
      "learning_rate": 1.658823529411765e-05,
      "loss": 0.1039,
      "step": 175
    },
    {
      "epoch": 1.7703703703703704,
      "grad_norm": 1.393344759941101,
      "learning_rate": 1.6490196078431374e-05,
      "loss": 0.0896,
      "step": 180
    },
    {
      "epoch": 1.819753086419753,
      "grad_norm": 3.355436325073242,
      "learning_rate": 1.63921568627451e-05,
      "loss": 0.0554,
      "step": 185
    },
    {
      "epoch": 1.8691358024691358,
      "grad_norm": 1.4614808559417725,
      "learning_rate": 1.6294117647058826e-05,
      "loss": 0.0423,
      "step": 190
    },
    {
      "epoch": 1.9185185185185185,
      "grad_norm": 4.440140724182129,
      "learning_rate": 1.619607843137255e-05,
      "loss": 0.0451,
      "step": 195
    },
    {
      "epoch": 1.9679012345679012,
      "grad_norm": 1.1581597328186035,
      "learning_rate": 1.6098039215686275e-05,
      "loss": 0.0565,
      "step": 200
    },
    {
      "epoch": 2.0098765432098764,
      "grad_norm": 0.5851479172706604,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 0.0238,
      "step": 205
    },
    {
      "epoch": 2.0592592592592593,
      "grad_norm": 1.5903055667877197,
      "learning_rate": 1.5901960784313727e-05,
      "loss": 0.0234,
      "step": 210
    },
    {
      "epoch": 2.108641975308642,
      "grad_norm": 1.8826005458831787,
      "learning_rate": 1.580392156862745e-05,
      "loss": 0.0174,
      "step": 215
    },
    {
      "epoch": 2.1580246913580248,
      "grad_norm": 0.9504191279411316,
      "learning_rate": 1.570588235294118e-05,
      "loss": 0.0139,
      "step": 220
    },
    {
      "epoch": 2.2074074074074073,
      "grad_norm": 0.308067262172699,
      "learning_rate": 1.5607843137254904e-05,
      "loss": 0.0099,
      "step": 225
    },
    {
      "epoch": 2.25679012345679,
      "grad_norm": 0.360137939453125,
      "learning_rate": 1.5509803921568628e-05,
      "loss": 0.0104,
      "step": 230
    },
    {
      "epoch": 2.3061728395061727,
      "grad_norm": 1.4959317445755005,
      "learning_rate": 1.5411764705882356e-05,
      "loss": 0.0173,
      "step": 235
    },
    {
      "epoch": 2.3555555555555556,
      "grad_norm": 1.2436625957489014,
      "learning_rate": 1.531372549019608e-05,
      "loss": 0.0091,
      "step": 240
    },
    {
      "epoch": 2.404938271604938,
      "grad_norm": 1.2710182666778564,
      "learning_rate": 1.5215686274509804e-05,
      "loss": 0.0072,
      "step": 245
    },
    {
      "epoch": 2.454320987654321,
      "grad_norm": 2.0713045597076416,
      "learning_rate": 1.511764705882353e-05,
      "loss": 0.0105,
      "step": 250
    },
    {
      "epoch": 2.5037037037037035,
      "grad_norm": 0.12925788760185242,
      "learning_rate": 1.5019607843137257e-05,
      "loss": 0.0198,
      "step": 255
    },
    {
      "epoch": 2.5530864197530865,
      "grad_norm": 2.387173652648926,
      "learning_rate": 1.4921568627450983e-05,
      "loss": 0.0092,
      "step": 260
    },
    {
      "epoch": 2.602469135802469,
      "grad_norm": 0.07514593750238419,
      "learning_rate": 1.4823529411764707e-05,
      "loss": 0.0094,
      "step": 265
    },
    {
      "epoch": 2.651851851851852,
      "grad_norm": 0.21462716162204742,
      "learning_rate": 1.4725490196078433e-05,
      "loss": 0.0055,
      "step": 270
    },
    {
      "epoch": 2.701234567901235,
      "grad_norm": 0.1345503330230713,
      "learning_rate": 1.4627450980392157e-05,
      "loss": 0.0041,
      "step": 275
    },
    {
      "epoch": 2.7506172839506173,
      "grad_norm": 0.1892070770263672,
      "learning_rate": 1.4529411764705883e-05,
      "loss": 0.007,
      "step": 280
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.22598831355571747,
      "learning_rate": 1.443137254901961e-05,
      "loss": 0.0039,
      "step": 285
    },
    {
      "epoch": 2.8493827160493828,
      "grad_norm": 0.3411387503147125,
      "learning_rate": 1.4333333333333334e-05,
      "loss": 0.0034,
      "step": 290
    },
    {
      "epoch": 2.8987654320987657,
      "grad_norm": 0.19289205968379974,
      "learning_rate": 1.423529411764706e-05,
      "loss": 0.0047,
      "step": 295
    },
    {
      "epoch": 2.948148148148148,
      "grad_norm": 0.5029206871986389,
      "learning_rate": 1.4137254901960786e-05,
      "loss": 0.0036,
      "step": 300
    },
    {
      "epoch": 2.9975308641975307,
      "grad_norm": 0.11229895800352097,
      "learning_rate": 1.403921568627451e-05,
      "loss": 0.0047,
      "step": 305
    }
  ],
  "logging_steps": 5,
  "max_steps": 1020,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 878067068534784.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
