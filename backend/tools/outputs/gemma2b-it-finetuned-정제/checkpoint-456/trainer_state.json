{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.0,
  "eval_steps": 500,
  "global_step": 456,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04395604395604396,
      "grad_norm": 7.632628440856934,
      "learning_rate": 1.992982456140351e-05,
      "loss": 4.9706,
      "step": 5
    },
    {
      "epoch": 0.08791208791208792,
      "grad_norm": 10.204829216003418,
      "learning_rate": 1.9842105263157895e-05,
      "loss": 5.0427,
      "step": 10
    },
    {
      "epoch": 0.13186813186813187,
      "grad_norm": 6.543023109436035,
      "learning_rate": 1.975438596491228e-05,
      "loss": 4.3929,
      "step": 15
    },
    {
      "epoch": 0.17582417582417584,
      "grad_norm": 4.795411109924316,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 3.9945,
      "step": 20
    },
    {
      "epoch": 0.21978021978021978,
      "grad_norm": 5.662419319152832,
      "learning_rate": 1.9578947368421055e-05,
      "loss": 3.9232,
      "step": 25
    },
    {
      "epoch": 0.26373626373626374,
      "grad_norm": 6.836350440979004,
      "learning_rate": 1.949122807017544e-05,
      "loss": 3.5501,
      "step": 30
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 5.145383358001709,
      "learning_rate": 1.9403508771929826e-05,
      "loss": 3.2291,
      "step": 35
    },
    {
      "epoch": 0.3516483516483517,
      "grad_norm": 5.933045864105225,
      "learning_rate": 1.931578947368421e-05,
      "loss": 3.1728,
      "step": 40
    },
    {
      "epoch": 0.3956043956043956,
      "grad_norm": 4.310506820678711,
      "learning_rate": 1.9228070175438597e-05,
      "loss": 2.8558,
      "step": 45
    },
    {
      "epoch": 0.43956043956043955,
      "grad_norm": 5.162708282470703,
      "learning_rate": 1.9140350877192982e-05,
      "loss": 2.6829,
      "step": 50
    },
    {
      "epoch": 0.4835164835164835,
      "grad_norm": 4.3355326652526855,
      "learning_rate": 1.9052631578947368e-05,
      "loss": 2.63,
      "step": 55
    },
    {
      "epoch": 0.5274725274725275,
      "grad_norm": 5.579771041870117,
      "learning_rate": 1.8964912280701757e-05,
      "loss": 2.347,
      "step": 60
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 4.0481085777282715,
      "learning_rate": 1.8877192982456142e-05,
      "loss": 2.5146,
      "step": 65
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 3.9540536403656006,
      "learning_rate": 1.8789473684210528e-05,
      "loss": 2.1364,
      "step": 70
    },
    {
      "epoch": 0.6593406593406593,
      "grad_norm": 3.6145615577697754,
      "learning_rate": 1.8701754385964913e-05,
      "loss": 1.9052,
      "step": 75
    },
    {
      "epoch": 0.7032967032967034,
      "grad_norm": 5.136443138122559,
      "learning_rate": 1.86140350877193e-05,
      "loss": 1.8857,
      "step": 80
    },
    {
      "epoch": 0.7472527472527473,
      "grad_norm": 5.177034854888916,
      "learning_rate": 1.8526315789473684e-05,
      "loss": 1.9232,
      "step": 85
    },
    {
      "epoch": 0.7912087912087912,
      "grad_norm": 4.925631046295166,
      "learning_rate": 1.843859649122807e-05,
      "loss": 1.684,
      "step": 90
    },
    {
      "epoch": 0.8351648351648352,
      "grad_norm": 4.752687454223633,
      "learning_rate": 1.835087719298246e-05,
      "loss": 1.4004,
      "step": 95
    },
    {
      "epoch": 0.8791208791208791,
      "grad_norm": 4.3822340965271,
      "learning_rate": 1.8263157894736844e-05,
      "loss": 1.3002,
      "step": 100
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 3.7708144187927246,
      "learning_rate": 1.817543859649123e-05,
      "loss": 1.3009,
      "step": 105
    },
    {
      "epoch": 0.967032967032967,
      "grad_norm": 4.843085765838623,
      "learning_rate": 1.8087719298245615e-05,
      "loss": 1.1255,
      "step": 110
    },
    {
      "epoch": 1.0087912087912088,
      "grad_norm": 4.558256149291992,
      "learning_rate": 1.8e-05,
      "loss": 0.9967,
      "step": 115
    },
    {
      "epoch": 1.0527472527472528,
      "grad_norm": 3.6430983543395996,
      "learning_rate": 1.7912280701754386e-05,
      "loss": 0.958,
      "step": 120
    },
    {
      "epoch": 1.0967032967032968,
      "grad_norm": 4.5930047035217285,
      "learning_rate": 1.7824561403508775e-05,
      "loss": 0.8737,
      "step": 125
    },
    {
      "epoch": 1.1406593406593406,
      "grad_norm": 4.398837089538574,
      "learning_rate": 1.773684210526316e-05,
      "loss": 0.717,
      "step": 130
    },
    {
      "epoch": 1.1846153846153846,
      "grad_norm": 3.7747857570648193,
      "learning_rate": 1.7649122807017546e-05,
      "loss": 0.6048,
      "step": 135
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 3.379318952560425,
      "learning_rate": 1.756140350877193e-05,
      "loss": 0.5595,
      "step": 140
    },
    {
      "epoch": 1.2725274725274724,
      "grad_norm": 8.305323600769043,
      "learning_rate": 1.7473684210526317e-05,
      "loss": 0.5482,
      "step": 145
    },
    {
      "epoch": 1.3164835164835165,
      "grad_norm": 3.1205520629882812,
      "learning_rate": 1.7385964912280702e-05,
      "loss": 0.3963,
      "step": 150
    },
    {
      "epoch": 1.3604395604395605,
      "grad_norm": 3.623042345046997,
      "learning_rate": 1.729824561403509e-05,
      "loss": 0.4974,
      "step": 155
    },
    {
      "epoch": 1.4043956043956043,
      "grad_norm": 3.9419546127319336,
      "learning_rate": 1.7210526315789477e-05,
      "loss": 0.3447,
      "step": 160
    },
    {
      "epoch": 1.4483516483516483,
      "grad_norm": 2.6911985874176025,
      "learning_rate": 1.7122807017543862e-05,
      "loss": 0.3277,
      "step": 165
    },
    {
      "epoch": 1.4923076923076923,
      "grad_norm": 2.6413733959198,
      "learning_rate": 1.7035087719298248e-05,
      "loss": 0.1998,
      "step": 170
    },
    {
      "epoch": 1.5362637362637361,
      "grad_norm": 2.2236506938934326,
      "learning_rate": 1.6947368421052633e-05,
      "loss": 0.1979,
      "step": 175
    },
    {
      "epoch": 1.5802197802197804,
      "grad_norm": 3.3767521381378174,
      "learning_rate": 1.685964912280702e-05,
      "loss": 0.2373,
      "step": 180
    },
    {
      "epoch": 1.6241758241758242,
      "grad_norm": 7.302035331726074,
      "learning_rate": 1.6771929824561408e-05,
      "loss": 0.2139,
      "step": 185
    },
    {
      "epoch": 1.668131868131868,
      "grad_norm": 5.802374362945557,
      "learning_rate": 1.6684210526315793e-05,
      "loss": 0.1904,
      "step": 190
    },
    {
      "epoch": 1.7120879120879122,
      "grad_norm": 2.0205039978027344,
      "learning_rate": 1.659649122807018e-05,
      "loss": 0.1488,
      "step": 195
    },
    {
      "epoch": 1.756043956043956,
      "grad_norm": 1.628744125366211,
      "learning_rate": 1.6508771929824564e-05,
      "loss": 0.0727,
      "step": 200
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.8950525522232056,
      "learning_rate": 1.642105263157895e-05,
      "loss": 0.1984,
      "step": 205
    },
    {
      "epoch": 1.843956043956044,
      "grad_norm": 3.969345808029175,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.298,
      "step": 210
    },
    {
      "epoch": 1.8879120879120879,
      "grad_norm": 0.6059702634811401,
      "learning_rate": 1.624561403508772e-05,
      "loss": 0.1464,
      "step": 215
    },
    {
      "epoch": 1.9318681318681319,
      "grad_norm": 1.4391834735870361,
      "learning_rate": 1.6157894736842106e-05,
      "loss": 0.156,
      "step": 220
    },
    {
      "epoch": 1.975824175824176,
      "grad_norm": 4.457927703857422,
      "learning_rate": 1.6070175438596495e-05,
      "loss": 0.2082,
      "step": 225
    },
    {
      "epoch": 2.0175824175824175,
      "grad_norm": 1.4818613529205322,
      "learning_rate": 1.598245614035088e-05,
      "loss": 0.1728,
      "step": 230
    },
    {
      "epoch": 2.0615384615384613,
      "grad_norm": 3.273311138153076,
      "learning_rate": 1.5894736842105266e-05,
      "loss": 0.0655,
      "step": 235
    },
    {
      "epoch": 2.1054945054945056,
      "grad_norm": 5.050691604614258,
      "learning_rate": 1.580701754385965e-05,
      "loss": 0.0529,
      "step": 240
    },
    {
      "epoch": 2.1494505494505494,
      "grad_norm": 1.5217852592468262,
      "learning_rate": 1.5719298245614037e-05,
      "loss": 0.0421,
      "step": 245
    },
    {
      "epoch": 2.1934065934065936,
      "grad_norm": 2.2277445793151855,
      "learning_rate": 1.5631578947368422e-05,
      "loss": 0.0467,
      "step": 250
    },
    {
      "epoch": 2.2373626373626374,
      "grad_norm": 1.0945029258728027,
      "learning_rate": 1.5543859649122808e-05,
      "loss": 0.1539,
      "step": 255
    },
    {
      "epoch": 2.281318681318681,
      "grad_norm": 0.3330499529838562,
      "learning_rate": 1.5456140350877193e-05,
      "loss": 0.0116,
      "step": 260
    },
    {
      "epoch": 2.3252747252747255,
      "grad_norm": 0.33633920550346375,
      "learning_rate": 1.536842105263158e-05,
      "loss": 0.1969,
      "step": 265
    },
    {
      "epoch": 2.3692307692307693,
      "grad_norm": 1.7622544765472412,
      "learning_rate": 1.5280701754385968e-05,
      "loss": 0.1458,
      "step": 270
    },
    {
      "epoch": 2.413186813186813,
      "grad_norm": 8.558029174804688,
      "learning_rate": 1.5192982456140353e-05,
      "loss": 0.1499,
      "step": 275
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 3.779808521270752,
      "learning_rate": 1.5105263157894739e-05,
      "loss": 0.093,
      "step": 280
    },
    {
      "epoch": 2.501098901098901,
      "grad_norm": 0.19316373765468597,
      "learning_rate": 1.5017543859649124e-05,
      "loss": 0.0056,
      "step": 285
    },
    {
      "epoch": 2.545054945054945,
      "grad_norm": 3.931030035018921,
      "learning_rate": 1.492982456140351e-05,
      "loss": 0.3403,
      "step": 290
    },
    {
      "epoch": 2.589010989010989,
      "grad_norm": 0.3251844644546509,
      "learning_rate": 1.4842105263157895e-05,
      "loss": 0.0048,
      "step": 295
    },
    {
      "epoch": 2.632967032967033,
      "grad_norm": 6.563008785247803,
      "learning_rate": 1.475438596491228e-05,
      "loss": 0.1976,
      "step": 300
    },
    {
      "epoch": 2.676923076923077,
      "grad_norm": 2.97345232963562,
      "learning_rate": 1.4666666666666666e-05,
      "loss": 0.2721,
      "step": 305
    },
    {
      "epoch": 2.720879120879121,
      "grad_norm": 1.038971185684204,
      "learning_rate": 1.4578947368421055e-05,
      "loss": 0.0374,
      "step": 310
    },
    {
      "epoch": 2.764835164835165,
      "grad_norm": 7.099576473236084,
      "learning_rate": 1.449122807017544e-05,
      "loss": 0.1223,
      "step": 315
    },
    {
      "epoch": 2.8087912087912086,
      "grad_norm": 0.5814926028251648,
      "learning_rate": 1.4403508771929826e-05,
      "loss": 0.0297,
      "step": 320
    },
    {
      "epoch": 2.852747252747253,
      "grad_norm": 1.4004911184310913,
      "learning_rate": 1.4315789473684212e-05,
      "loss": 0.0483,
      "step": 325
    },
    {
      "epoch": 2.8967032967032966,
      "grad_norm": 2.472564935684204,
      "learning_rate": 1.4228070175438597e-05,
      "loss": 0.1086,
      "step": 330
    },
    {
      "epoch": 2.940659340659341,
      "grad_norm": 0.3546336591243744,
      "learning_rate": 1.4140350877192983e-05,
      "loss": 0.0821,
      "step": 335
    },
    {
      "epoch": 2.9846153846153847,
      "grad_norm": 4.938849925994873,
      "learning_rate": 1.4052631578947368e-05,
      "loss": 0.25,
      "step": 340
    },
    {
      "epoch": 3.0263736263736263,
      "grad_norm": 0.19567838311195374,
      "learning_rate": 1.3964912280701755e-05,
      "loss": 0.0083,
      "step": 345
    },
    {
      "epoch": 3.0703296703296705,
      "grad_norm": 1.8442906141281128,
      "learning_rate": 1.3877192982456143e-05,
      "loss": 0.1167,
      "step": 350
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 4.092510223388672,
      "learning_rate": 1.3789473684210528e-05,
      "loss": 0.1912,
      "step": 355
    },
    {
      "epoch": 3.158241758241758,
      "grad_norm": 3.333314895629883,
      "learning_rate": 1.3701754385964914e-05,
      "loss": 0.0872,
      "step": 360
    },
    {
      "epoch": 3.2021978021978024,
      "grad_norm": 0.1457909494638443,
      "learning_rate": 1.3614035087719299e-05,
      "loss": 0.0038,
      "step": 365
    },
    {
      "epoch": 3.246153846153846,
      "grad_norm": 0.44140809774398804,
      "learning_rate": 1.3526315789473685e-05,
      "loss": 0.1235,
      "step": 370
    },
    {
      "epoch": 3.29010989010989,
      "grad_norm": 2.297497272491455,
      "learning_rate": 1.343859649122807e-05,
      "loss": 0.0227,
      "step": 375
    },
    {
      "epoch": 3.334065934065934,
      "grad_norm": 0.12780290842056274,
      "learning_rate": 1.3350877192982457e-05,
      "loss": 0.0488,
      "step": 380
    },
    {
      "epoch": 3.378021978021978,
      "grad_norm": 4.589734077453613,
      "learning_rate": 1.3263157894736843e-05,
      "loss": 0.1234,
      "step": 385
    },
    {
      "epoch": 3.421978021978022,
      "grad_norm": 0.9696006178855896,
      "learning_rate": 1.317543859649123e-05,
      "loss": 0.0075,
      "step": 390
    },
    {
      "epoch": 3.465934065934066,
      "grad_norm": 3.6690473556518555,
      "learning_rate": 1.3087719298245615e-05,
      "loss": 0.2726,
      "step": 395
    },
    {
      "epoch": 3.50989010989011,
      "grad_norm": 0.13509875535964966,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0952,
      "step": 400
    },
    {
      "epoch": 3.5538461538461537,
      "grad_norm": 0.08985423296689987,
      "learning_rate": 1.2912280701754386e-05,
      "loss": 0.0531,
      "step": 405
    },
    {
      "epoch": 3.597802197802198,
      "grad_norm": 0.09762627631425858,
      "learning_rate": 1.2824561403508774e-05,
      "loss": 0.0039,
      "step": 410
    },
    {
      "epoch": 3.6417582417582417,
      "grad_norm": 0.06926028430461884,
      "learning_rate": 1.2736842105263159e-05,
      "loss": 0.1292,
      "step": 415
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.24206703901290894,
      "learning_rate": 1.2649122807017545e-05,
      "loss": 0.0189,
      "step": 420
    },
    {
      "epoch": 3.7296703296703297,
      "grad_norm": 1.8938612937927246,
      "learning_rate": 1.256140350877193e-05,
      "loss": 0.0186,
      "step": 425
    },
    {
      "epoch": 3.7736263736263735,
      "grad_norm": 0.15356554090976715,
      "learning_rate": 1.2473684210526317e-05,
      "loss": 0.028,
      "step": 430
    },
    {
      "epoch": 3.8175824175824173,
      "grad_norm": 0.2776655852794647,
      "learning_rate": 1.2385964912280703e-05,
      "loss": 0.1024,
      "step": 435
    },
    {
      "epoch": 3.8615384615384616,
      "grad_norm": 0.08000427484512329,
      "learning_rate": 1.229824561403509e-05,
      "loss": 0.0255,
      "step": 440
    },
    {
      "epoch": 3.9054945054945054,
      "grad_norm": 0.1689855456352234,
      "learning_rate": 1.2210526315789475e-05,
      "loss": 0.113,
      "step": 445
    },
    {
      "epoch": 3.9494505494505496,
      "grad_norm": 2.6166887283325195,
      "learning_rate": 1.2122807017543861e-05,
      "loss": 0.1066,
      "step": 450
    },
    {
      "epoch": 3.9934065934065934,
      "grad_norm": 0.05833955854177475,
      "learning_rate": 1.2035087719298246e-05,
      "loss": 0.0488,
      "step": 455
    }
  ],
  "logging_steps": 5,
  "max_steps": 1140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1272163164094464.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
