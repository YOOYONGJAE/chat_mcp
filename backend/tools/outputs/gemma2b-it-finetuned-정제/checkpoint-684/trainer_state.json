{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 684,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04395604395604396,
      "grad_norm": 7.632628440856934,
      "learning_rate": 1.992982456140351e-05,
      "loss": 4.9706,
      "step": 5
    },
    {
      "epoch": 0.08791208791208792,
      "grad_norm": 10.204829216003418,
      "learning_rate": 1.9842105263157895e-05,
      "loss": 5.0427,
      "step": 10
    },
    {
      "epoch": 0.13186813186813187,
      "grad_norm": 6.543023109436035,
      "learning_rate": 1.975438596491228e-05,
      "loss": 4.3929,
      "step": 15
    },
    {
      "epoch": 0.17582417582417584,
      "grad_norm": 4.795411109924316,
      "learning_rate": 1.9666666666666666e-05,
      "loss": 3.9945,
      "step": 20
    },
    {
      "epoch": 0.21978021978021978,
      "grad_norm": 5.662419319152832,
      "learning_rate": 1.9578947368421055e-05,
      "loss": 3.9232,
      "step": 25
    },
    {
      "epoch": 0.26373626373626374,
      "grad_norm": 6.836350440979004,
      "learning_rate": 1.949122807017544e-05,
      "loss": 3.5501,
      "step": 30
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 5.145383358001709,
      "learning_rate": 1.9403508771929826e-05,
      "loss": 3.2291,
      "step": 35
    },
    {
      "epoch": 0.3516483516483517,
      "grad_norm": 5.933045864105225,
      "learning_rate": 1.931578947368421e-05,
      "loss": 3.1728,
      "step": 40
    },
    {
      "epoch": 0.3956043956043956,
      "grad_norm": 4.310506820678711,
      "learning_rate": 1.9228070175438597e-05,
      "loss": 2.8558,
      "step": 45
    },
    {
      "epoch": 0.43956043956043955,
      "grad_norm": 5.162708282470703,
      "learning_rate": 1.9140350877192982e-05,
      "loss": 2.6829,
      "step": 50
    },
    {
      "epoch": 0.4835164835164835,
      "grad_norm": 4.3355326652526855,
      "learning_rate": 1.9052631578947368e-05,
      "loss": 2.63,
      "step": 55
    },
    {
      "epoch": 0.5274725274725275,
      "grad_norm": 5.579771041870117,
      "learning_rate": 1.8964912280701757e-05,
      "loss": 2.347,
      "step": 60
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 4.0481085777282715,
      "learning_rate": 1.8877192982456142e-05,
      "loss": 2.5146,
      "step": 65
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 3.9540536403656006,
      "learning_rate": 1.8789473684210528e-05,
      "loss": 2.1364,
      "step": 70
    },
    {
      "epoch": 0.6593406593406593,
      "grad_norm": 3.6145615577697754,
      "learning_rate": 1.8701754385964913e-05,
      "loss": 1.9052,
      "step": 75
    },
    {
      "epoch": 0.7032967032967034,
      "grad_norm": 5.136443138122559,
      "learning_rate": 1.86140350877193e-05,
      "loss": 1.8857,
      "step": 80
    },
    {
      "epoch": 0.7472527472527473,
      "grad_norm": 5.177034854888916,
      "learning_rate": 1.8526315789473684e-05,
      "loss": 1.9232,
      "step": 85
    },
    {
      "epoch": 0.7912087912087912,
      "grad_norm": 4.925631046295166,
      "learning_rate": 1.843859649122807e-05,
      "loss": 1.684,
      "step": 90
    },
    {
      "epoch": 0.8351648351648352,
      "grad_norm": 4.752687454223633,
      "learning_rate": 1.835087719298246e-05,
      "loss": 1.4004,
      "step": 95
    },
    {
      "epoch": 0.8791208791208791,
      "grad_norm": 4.3822340965271,
      "learning_rate": 1.8263157894736844e-05,
      "loss": 1.3002,
      "step": 100
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 3.7708144187927246,
      "learning_rate": 1.817543859649123e-05,
      "loss": 1.3009,
      "step": 105
    },
    {
      "epoch": 0.967032967032967,
      "grad_norm": 4.843085765838623,
      "learning_rate": 1.8087719298245615e-05,
      "loss": 1.1255,
      "step": 110
    },
    {
      "epoch": 1.0087912087912088,
      "grad_norm": 4.558256149291992,
      "learning_rate": 1.8e-05,
      "loss": 0.9967,
      "step": 115
    },
    {
      "epoch": 1.0527472527472528,
      "grad_norm": 3.6430983543395996,
      "learning_rate": 1.7912280701754386e-05,
      "loss": 0.958,
      "step": 120
    },
    {
      "epoch": 1.0967032967032968,
      "grad_norm": 4.5930047035217285,
      "learning_rate": 1.7824561403508775e-05,
      "loss": 0.8737,
      "step": 125
    },
    {
      "epoch": 1.1406593406593406,
      "grad_norm": 4.398837089538574,
      "learning_rate": 1.773684210526316e-05,
      "loss": 0.717,
      "step": 130
    },
    {
      "epoch": 1.1846153846153846,
      "grad_norm": 3.7747857570648193,
      "learning_rate": 1.7649122807017546e-05,
      "loss": 0.6048,
      "step": 135
    },
    {
      "epoch": 1.2285714285714286,
      "grad_norm": 3.379318952560425,
      "learning_rate": 1.756140350877193e-05,
      "loss": 0.5595,
      "step": 140
    },
    {
      "epoch": 1.2725274725274724,
      "grad_norm": 8.305323600769043,
      "learning_rate": 1.7473684210526317e-05,
      "loss": 0.5482,
      "step": 145
    },
    {
      "epoch": 1.3164835164835165,
      "grad_norm": 3.1205520629882812,
      "learning_rate": 1.7385964912280702e-05,
      "loss": 0.3963,
      "step": 150
    },
    {
      "epoch": 1.3604395604395605,
      "grad_norm": 3.623042345046997,
      "learning_rate": 1.729824561403509e-05,
      "loss": 0.4974,
      "step": 155
    },
    {
      "epoch": 1.4043956043956043,
      "grad_norm": 3.9419546127319336,
      "learning_rate": 1.7210526315789477e-05,
      "loss": 0.3447,
      "step": 160
    },
    {
      "epoch": 1.4483516483516483,
      "grad_norm": 2.6911985874176025,
      "learning_rate": 1.7122807017543862e-05,
      "loss": 0.3277,
      "step": 165
    },
    {
      "epoch": 1.4923076923076923,
      "grad_norm": 2.6413733959198,
      "learning_rate": 1.7035087719298248e-05,
      "loss": 0.1998,
      "step": 170
    },
    {
      "epoch": 1.5362637362637361,
      "grad_norm": 2.2236506938934326,
      "learning_rate": 1.6947368421052633e-05,
      "loss": 0.1979,
      "step": 175
    },
    {
      "epoch": 1.5802197802197804,
      "grad_norm": 3.3767521381378174,
      "learning_rate": 1.685964912280702e-05,
      "loss": 0.2373,
      "step": 180
    },
    {
      "epoch": 1.6241758241758242,
      "grad_norm": 7.302035331726074,
      "learning_rate": 1.6771929824561408e-05,
      "loss": 0.2139,
      "step": 185
    },
    {
      "epoch": 1.668131868131868,
      "grad_norm": 5.802374362945557,
      "learning_rate": 1.6684210526315793e-05,
      "loss": 0.1904,
      "step": 190
    },
    {
      "epoch": 1.7120879120879122,
      "grad_norm": 2.0205039978027344,
      "learning_rate": 1.659649122807018e-05,
      "loss": 0.1488,
      "step": 195
    },
    {
      "epoch": 1.756043956043956,
      "grad_norm": 1.628744125366211,
      "learning_rate": 1.6508771929824564e-05,
      "loss": 0.0727,
      "step": 200
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.8950525522232056,
      "learning_rate": 1.642105263157895e-05,
      "loss": 0.1984,
      "step": 205
    },
    {
      "epoch": 1.843956043956044,
      "grad_norm": 3.969345808029175,
      "learning_rate": 1.6333333333333335e-05,
      "loss": 0.298,
      "step": 210
    },
    {
      "epoch": 1.8879120879120879,
      "grad_norm": 0.6059702634811401,
      "learning_rate": 1.624561403508772e-05,
      "loss": 0.1464,
      "step": 215
    },
    {
      "epoch": 1.9318681318681319,
      "grad_norm": 1.4391834735870361,
      "learning_rate": 1.6157894736842106e-05,
      "loss": 0.156,
      "step": 220
    },
    {
      "epoch": 1.975824175824176,
      "grad_norm": 4.457927703857422,
      "learning_rate": 1.6070175438596495e-05,
      "loss": 0.2082,
      "step": 225
    },
    {
      "epoch": 2.0175824175824175,
      "grad_norm": 1.4818613529205322,
      "learning_rate": 1.598245614035088e-05,
      "loss": 0.1728,
      "step": 230
    },
    {
      "epoch": 2.0615384615384613,
      "grad_norm": 3.273311138153076,
      "learning_rate": 1.5894736842105266e-05,
      "loss": 0.0655,
      "step": 235
    },
    {
      "epoch": 2.1054945054945056,
      "grad_norm": 5.050691604614258,
      "learning_rate": 1.580701754385965e-05,
      "loss": 0.0529,
      "step": 240
    },
    {
      "epoch": 2.1494505494505494,
      "grad_norm": 1.5217852592468262,
      "learning_rate": 1.5719298245614037e-05,
      "loss": 0.0421,
      "step": 245
    },
    {
      "epoch": 2.1934065934065936,
      "grad_norm": 2.2277445793151855,
      "learning_rate": 1.5631578947368422e-05,
      "loss": 0.0467,
      "step": 250
    },
    {
      "epoch": 2.2373626373626374,
      "grad_norm": 1.0945029258728027,
      "learning_rate": 1.5543859649122808e-05,
      "loss": 0.1539,
      "step": 255
    },
    {
      "epoch": 2.281318681318681,
      "grad_norm": 0.3330499529838562,
      "learning_rate": 1.5456140350877193e-05,
      "loss": 0.0116,
      "step": 260
    },
    {
      "epoch": 2.3252747252747255,
      "grad_norm": 0.33633920550346375,
      "learning_rate": 1.536842105263158e-05,
      "loss": 0.1969,
      "step": 265
    },
    {
      "epoch": 2.3692307692307693,
      "grad_norm": 1.7622544765472412,
      "learning_rate": 1.5280701754385968e-05,
      "loss": 0.1458,
      "step": 270
    },
    {
      "epoch": 2.413186813186813,
      "grad_norm": 8.558029174804688,
      "learning_rate": 1.5192982456140353e-05,
      "loss": 0.1499,
      "step": 275
    },
    {
      "epoch": 2.4571428571428573,
      "grad_norm": 3.779808521270752,
      "learning_rate": 1.5105263157894739e-05,
      "loss": 0.093,
      "step": 280
    },
    {
      "epoch": 2.501098901098901,
      "grad_norm": 0.19316373765468597,
      "learning_rate": 1.5017543859649124e-05,
      "loss": 0.0056,
      "step": 285
    },
    {
      "epoch": 2.545054945054945,
      "grad_norm": 3.931030035018921,
      "learning_rate": 1.492982456140351e-05,
      "loss": 0.3403,
      "step": 290
    },
    {
      "epoch": 2.589010989010989,
      "grad_norm": 0.3251844644546509,
      "learning_rate": 1.4842105263157895e-05,
      "loss": 0.0048,
      "step": 295
    },
    {
      "epoch": 2.632967032967033,
      "grad_norm": 6.563008785247803,
      "learning_rate": 1.475438596491228e-05,
      "loss": 0.1976,
      "step": 300
    },
    {
      "epoch": 2.676923076923077,
      "grad_norm": 2.97345232963562,
      "learning_rate": 1.4666666666666666e-05,
      "loss": 0.2721,
      "step": 305
    },
    {
      "epoch": 2.720879120879121,
      "grad_norm": 1.038971185684204,
      "learning_rate": 1.4578947368421055e-05,
      "loss": 0.0374,
      "step": 310
    },
    {
      "epoch": 2.764835164835165,
      "grad_norm": 7.099576473236084,
      "learning_rate": 1.449122807017544e-05,
      "loss": 0.1223,
      "step": 315
    },
    {
      "epoch": 2.8087912087912086,
      "grad_norm": 0.5814926028251648,
      "learning_rate": 1.4403508771929826e-05,
      "loss": 0.0297,
      "step": 320
    },
    {
      "epoch": 2.852747252747253,
      "grad_norm": 1.4004911184310913,
      "learning_rate": 1.4315789473684212e-05,
      "loss": 0.0483,
      "step": 325
    },
    {
      "epoch": 2.8967032967032966,
      "grad_norm": 2.472564935684204,
      "learning_rate": 1.4228070175438597e-05,
      "loss": 0.1086,
      "step": 330
    },
    {
      "epoch": 2.940659340659341,
      "grad_norm": 0.3546336591243744,
      "learning_rate": 1.4140350877192983e-05,
      "loss": 0.0821,
      "step": 335
    },
    {
      "epoch": 2.9846153846153847,
      "grad_norm": 4.938849925994873,
      "learning_rate": 1.4052631578947368e-05,
      "loss": 0.25,
      "step": 340
    },
    {
      "epoch": 3.0263736263736263,
      "grad_norm": 0.19567838311195374,
      "learning_rate": 1.3964912280701755e-05,
      "loss": 0.0083,
      "step": 345
    },
    {
      "epoch": 3.0703296703296705,
      "grad_norm": 1.8442906141281128,
      "learning_rate": 1.3877192982456143e-05,
      "loss": 0.1167,
      "step": 350
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 4.092510223388672,
      "learning_rate": 1.3789473684210528e-05,
      "loss": 0.1912,
      "step": 355
    },
    {
      "epoch": 3.158241758241758,
      "grad_norm": 3.333314895629883,
      "learning_rate": 1.3701754385964914e-05,
      "loss": 0.0872,
      "step": 360
    },
    {
      "epoch": 3.2021978021978024,
      "grad_norm": 0.1457909494638443,
      "learning_rate": 1.3614035087719299e-05,
      "loss": 0.0038,
      "step": 365
    },
    {
      "epoch": 3.246153846153846,
      "grad_norm": 0.44140809774398804,
      "learning_rate": 1.3526315789473685e-05,
      "loss": 0.1235,
      "step": 370
    },
    {
      "epoch": 3.29010989010989,
      "grad_norm": 2.297497272491455,
      "learning_rate": 1.343859649122807e-05,
      "loss": 0.0227,
      "step": 375
    },
    {
      "epoch": 3.334065934065934,
      "grad_norm": 0.12780290842056274,
      "learning_rate": 1.3350877192982457e-05,
      "loss": 0.0488,
      "step": 380
    },
    {
      "epoch": 3.378021978021978,
      "grad_norm": 4.589734077453613,
      "learning_rate": 1.3263157894736843e-05,
      "loss": 0.1234,
      "step": 385
    },
    {
      "epoch": 3.421978021978022,
      "grad_norm": 0.9696006178855896,
      "learning_rate": 1.317543859649123e-05,
      "loss": 0.0075,
      "step": 390
    },
    {
      "epoch": 3.465934065934066,
      "grad_norm": 3.6690473556518555,
      "learning_rate": 1.3087719298245615e-05,
      "loss": 0.2726,
      "step": 395
    },
    {
      "epoch": 3.50989010989011,
      "grad_norm": 0.13509875535964966,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 0.0952,
      "step": 400
    },
    {
      "epoch": 3.5538461538461537,
      "grad_norm": 0.08985423296689987,
      "learning_rate": 1.2912280701754386e-05,
      "loss": 0.0531,
      "step": 405
    },
    {
      "epoch": 3.597802197802198,
      "grad_norm": 0.09762627631425858,
      "learning_rate": 1.2824561403508774e-05,
      "loss": 0.0039,
      "step": 410
    },
    {
      "epoch": 3.6417582417582417,
      "grad_norm": 0.06926028430461884,
      "learning_rate": 1.2736842105263159e-05,
      "loss": 0.1292,
      "step": 415
    },
    {
      "epoch": 3.685714285714286,
      "grad_norm": 0.24206703901290894,
      "learning_rate": 1.2649122807017545e-05,
      "loss": 0.0189,
      "step": 420
    },
    {
      "epoch": 3.7296703296703297,
      "grad_norm": 1.8938612937927246,
      "learning_rate": 1.256140350877193e-05,
      "loss": 0.0186,
      "step": 425
    },
    {
      "epoch": 3.7736263736263735,
      "grad_norm": 0.15356554090976715,
      "learning_rate": 1.2473684210526317e-05,
      "loss": 0.028,
      "step": 430
    },
    {
      "epoch": 3.8175824175824173,
      "grad_norm": 0.2776655852794647,
      "learning_rate": 1.2385964912280703e-05,
      "loss": 0.1024,
      "step": 435
    },
    {
      "epoch": 3.8615384615384616,
      "grad_norm": 0.08000427484512329,
      "learning_rate": 1.229824561403509e-05,
      "loss": 0.0255,
      "step": 440
    },
    {
      "epoch": 3.9054945054945054,
      "grad_norm": 0.1689855456352234,
      "learning_rate": 1.2210526315789475e-05,
      "loss": 0.113,
      "step": 445
    },
    {
      "epoch": 3.9494505494505496,
      "grad_norm": 2.6166887283325195,
      "learning_rate": 1.2122807017543861e-05,
      "loss": 0.1066,
      "step": 450
    },
    {
      "epoch": 3.9934065934065934,
      "grad_norm": 0.05833955854177475,
      "learning_rate": 1.2035087719298246e-05,
      "loss": 0.0488,
      "step": 455
    },
    {
      "epoch": 4.035164835164835,
      "grad_norm": 3.0518414974212646,
      "learning_rate": 1.1947368421052632e-05,
      "loss": 0.022,
      "step": 460
    },
    {
      "epoch": 4.079120879120879,
      "grad_norm": 6.258166790008545,
      "learning_rate": 1.1859649122807017e-05,
      "loss": 0.2161,
      "step": 465
    },
    {
      "epoch": 4.123076923076923,
      "grad_norm": 3.0860867500305176,
      "learning_rate": 1.1771929824561406e-05,
      "loss": 0.1122,
      "step": 470
    },
    {
      "epoch": 4.167032967032967,
      "grad_norm": 3.282766342163086,
      "learning_rate": 1.1684210526315792e-05,
      "loss": 0.0754,
      "step": 475
    },
    {
      "epoch": 4.210989010989011,
      "grad_norm": 0.184810608625412,
      "learning_rate": 1.1596491228070177e-05,
      "loss": 0.0539,
      "step": 480
    },
    {
      "epoch": 4.254945054945055,
      "grad_norm": 0.37149348855018616,
      "learning_rate": 1.1508771929824563e-05,
      "loss": 0.094,
      "step": 485
    },
    {
      "epoch": 4.298901098901099,
      "grad_norm": 0.19283495843410492,
      "learning_rate": 1.1421052631578948e-05,
      "loss": 0.0196,
      "step": 490
    },
    {
      "epoch": 4.3428571428571425,
      "grad_norm": 0.08094798028469086,
      "learning_rate": 1.1333333333333334e-05,
      "loss": 0.0147,
      "step": 495
    },
    {
      "epoch": 4.386813186813187,
      "grad_norm": 0.08714567124843597,
      "learning_rate": 1.124561403508772e-05,
      "loss": 0.0613,
      "step": 500
    },
    {
      "epoch": 4.430769230769231,
      "grad_norm": 3.76997971534729,
      "learning_rate": 1.1157894736842105e-05,
      "loss": 0.1162,
      "step": 505
    },
    {
      "epoch": 4.474725274725275,
      "grad_norm": 0.044161807745695114,
      "learning_rate": 1.1070175438596494e-05,
      "loss": 0.0631,
      "step": 510
    },
    {
      "epoch": 4.518681318681319,
      "grad_norm": 4.210544109344482,
      "learning_rate": 1.098245614035088e-05,
      "loss": 0.1547,
      "step": 515
    },
    {
      "epoch": 4.562637362637362,
      "grad_norm": 2.674591064453125,
      "learning_rate": 1.0894736842105265e-05,
      "loss": 0.1213,
      "step": 520
    },
    {
      "epoch": 4.606593406593406,
      "grad_norm": 0.09704169631004333,
      "learning_rate": 1.080701754385965e-05,
      "loss": 0.0017,
      "step": 525
    },
    {
      "epoch": 4.650549450549451,
      "grad_norm": 0.12156402319669724,
      "learning_rate": 1.0719298245614036e-05,
      "loss": 0.0485,
      "step": 530
    },
    {
      "epoch": 4.694505494505495,
      "grad_norm": 0.14506196975708008,
      "learning_rate": 1.0631578947368421e-05,
      "loss": 0.0021,
      "step": 535
    },
    {
      "epoch": 4.7384615384615385,
      "grad_norm": 0.11218210309743881,
      "learning_rate": 1.0543859649122807e-05,
      "loss": 0.048,
      "step": 540
    },
    {
      "epoch": 4.782417582417582,
      "grad_norm": 2.331880569458008,
      "learning_rate": 1.0456140350877194e-05,
      "loss": 0.0488,
      "step": 545
    },
    {
      "epoch": 4.826373626373626,
      "grad_norm": 5.757595062255859,
      "learning_rate": 1.036842105263158e-05,
      "loss": 0.0642,
      "step": 550
    },
    {
      "epoch": 4.870329670329671,
      "grad_norm": 0.4308496117591858,
      "learning_rate": 1.0280701754385967e-05,
      "loss": 0.0409,
      "step": 555
    },
    {
      "epoch": 4.914285714285715,
      "grad_norm": 0.13844582438468933,
      "learning_rate": 1.0192982456140352e-05,
      "loss": 0.0404,
      "step": 560
    },
    {
      "epoch": 4.958241758241758,
      "grad_norm": 5.06481409072876,
      "learning_rate": 1.0105263157894738e-05,
      "loss": 0.0793,
      "step": 565
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.0756172239780426,
      "learning_rate": 1.0017543859649123e-05,
      "loss": 0.0484,
      "step": 570
    },
    {
      "epoch": 5.043956043956044,
      "grad_norm": 0.46344998478889465,
      "learning_rate": 9.929824561403509e-06,
      "loss": 0.0693,
      "step": 575
    },
    {
      "epoch": 5.087912087912088,
      "grad_norm": 3.821944236755371,
      "learning_rate": 9.842105263157896e-06,
      "loss": 0.0782,
      "step": 580
    },
    {
      "epoch": 5.131868131868132,
      "grad_norm": 0.24360089004039764,
      "learning_rate": 9.754385964912281e-06,
      "loss": 0.0242,
      "step": 585
    },
    {
      "epoch": 5.175824175824176,
      "grad_norm": 0.06546422094106674,
      "learning_rate": 9.666666666666667e-06,
      "loss": 0.0771,
      "step": 590
    },
    {
      "epoch": 5.21978021978022,
      "grad_norm": 6.692684650421143,
      "learning_rate": 9.578947368421054e-06,
      "loss": 0.1265,
      "step": 595
    },
    {
      "epoch": 5.263736263736264,
      "grad_norm": 0.27207785844802856,
      "learning_rate": 9.49122807017544e-06,
      "loss": 0.0296,
      "step": 600
    },
    {
      "epoch": 5.3076923076923075,
      "grad_norm": 0.0920027419924736,
      "learning_rate": 9.403508771929825e-06,
      "loss": 0.0449,
      "step": 605
    },
    {
      "epoch": 5.351648351648351,
      "grad_norm": 0.060158759355545044,
      "learning_rate": 9.315789473684212e-06,
      "loss": 0.0008,
      "step": 610
    },
    {
      "epoch": 5.395604395604396,
      "grad_norm": 0.07381701469421387,
      "learning_rate": 9.228070175438598e-06,
      "loss": 0.0149,
      "step": 615
    },
    {
      "epoch": 5.43956043956044,
      "grad_norm": 0.0953250601887703,
      "learning_rate": 9.140350877192983e-06,
      "loss": 0.0691,
      "step": 620
    },
    {
      "epoch": 5.483516483516484,
      "grad_norm": 4.673946380615234,
      "learning_rate": 9.05263157894737e-06,
      "loss": 0.0443,
      "step": 625
    },
    {
      "epoch": 5.527472527472527,
      "grad_norm": 0.19057518243789673,
      "learning_rate": 8.964912280701756e-06,
      "loss": 0.0436,
      "step": 630
    },
    {
      "epoch": 5.571428571428571,
      "grad_norm": 0.13605496287345886,
      "learning_rate": 8.877192982456141e-06,
      "loss": 0.0642,
      "step": 635
    },
    {
      "epoch": 5.615384615384615,
      "grad_norm": 1.0015085935592651,
      "learning_rate": 8.789473684210527e-06,
      "loss": 0.0291,
      "step": 640
    },
    {
      "epoch": 5.65934065934066,
      "grad_norm": 1.5584715604782104,
      "learning_rate": 8.701754385964914e-06,
      "loss": 0.0682,
      "step": 645
    },
    {
      "epoch": 5.7032967032967035,
      "grad_norm": 0.06103307753801346,
      "learning_rate": 8.6140350877193e-06,
      "loss": 0.0686,
      "step": 650
    },
    {
      "epoch": 5.747252747252747,
      "grad_norm": 0.17775215208530426,
      "learning_rate": 8.526315789473685e-06,
      "loss": 0.0615,
      "step": 655
    },
    {
      "epoch": 5.791208791208791,
      "grad_norm": 4.862475872039795,
      "learning_rate": 8.43859649122807e-06,
      "loss": 0.0657,
      "step": 660
    },
    {
      "epoch": 5.835164835164835,
      "grad_norm": 2.337973117828369,
      "learning_rate": 8.350877192982458e-06,
      "loss": 0.066,
      "step": 665
    },
    {
      "epoch": 5.8791208791208796,
      "grad_norm": 0.13035623729228973,
      "learning_rate": 8.263157894736843e-06,
      "loss": 0.0011,
      "step": 670
    },
    {
      "epoch": 5.923076923076923,
      "grad_norm": 3.9594411849975586,
      "learning_rate": 8.175438596491229e-06,
      "loss": 0.0203,
      "step": 675
    },
    {
      "epoch": 5.967032967032967,
      "grad_norm": 0.06817182153463364,
      "learning_rate": 8.087719298245614e-06,
      "loss": 0.124,
      "step": 680
    }
  ],
  "logging_steps": 5,
  "max_steps": 1140,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1908244746141696.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
